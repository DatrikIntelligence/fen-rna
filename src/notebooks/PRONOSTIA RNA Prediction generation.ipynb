{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import models\n",
    "import scoring\n",
    "from data import pronostia\n",
    "import gc \n",
    "import pickle as pk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('../data/pronostia/pronostia_train.csv')\n",
    "data2 = pd.read_csv('../data/pronostia/pronostia_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUL = pd.concat((data1, data2))[['Bearing', 'Condition', 'RUL']]\n",
    "del data1\n",
    "del data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MODELS = {\n",
    "    'cnn_cnn_rna': ('e1bdbbece8a83a8965807683b4a1c454dc201a33', \n",
    "                    'net_cnn_l2_pronostia_embeddings_fold', \n",
    "                    'mscnn_pronostia', 110),\n",
    "    'cnn_rnn_rna': ('2b8549cb2dca448b403924a090b3ee20ae96e536', \n",
    "                    'net_cnn_rnn_rna_pronostia_embeddings_fold', \n",
    "                    'mscnn_pronostia', 110),\n",
    "    'rnn_rnn_rna': ('f6754f479fd9939af8fca7c4f8645a041bb96225',\n",
    "                    'net_rnn_rnn_rna_pronostia_embeddings_fold',\n",
    "                    'rnn_pronostia', 122),\n",
    "    'rnn_cnn_rna': ('d6edaa0ccb4fd9fb38137e7c4f33730dab36fa27',\n",
    "                    'net_rnn_cnn_rna_rnn_pronostia_embeddings_fold',\n",
    "                    'rnn_pronostia', 122)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "_dir = 'rnn_cnn_rna'\n",
    "\n",
    "code, file, embeddings_dir, window = MODELS[_dir]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_1:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "163/163 [==============================] - 12s 75ms/step\n",
      "86/86 [==============================] - 7s 77ms/step\n",
      "79/79 [==============================] - 6s 73ms/step\n",
      "113/113 [==============================] - 9s 76ms/step\n",
      "61/61 [==============================] - 4s 73ms/step\n",
      "200/200 [==============================] - 15s 75ms/step\n",
      "  2/230 [..............................] - ETA: 2:40WARNING:tensorflow:Method (on_predict_batch_end) is slow compared to the batch update (0.755798). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_predict_batch_end) is slow compared to the batch update (0.755798). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 21s 91ms/step\n",
      "[<tf.Tensor 'input_1_1:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "90/90 [==============================] - 7s 72ms/step\n",
      "51/51 [==============================] - 5s 105ms/step\n",
      "280/280 [==============================] - 21s 73ms/step\n",
      "120/120 [==============================] - 9s 72ms/step\n",
      "35/35 [==============================] - 2s 69ms/step\n",
      "180/180 [==============================] - 13s 73ms/step\n",
      "  2/230 [..............................] - ETA: 8:32WARNING:tensorflow:Method (on_predict_batch_end) is slow compared to the batch update (1.804791). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_predict_batch_end) is slow compared to the batch update (1.804791). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 26s 115ms/step\n",
      "57/57 [==============================] - 4s 75ms/step\n",
      "[<tf.Tensor 'input_1_2:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "163/163 [==============================] - 14s 84ms/step\n",
      "86/86 [==============================] - 10s 121ms/step\n",
      "79/79 [==============================] - 6s 71ms/step\n",
      "230/230 [==============================] - 17s 72ms/step\n",
      "57/57 [==============================] - 4s 71ms/step\n",
      "150/150 [==============================] - 11s 73ms/step\n",
      "17/17 [==============================] - 1s 64ms/step\n",
      "[<tf.Tensor 'input_1_3:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "90/90 [==============================] - 7s 73ms/step\n",
      "51/51 [==============================] - 4s 72ms/step\n",
      "280/280 [==============================] - 21s 73ms/step\n",
      "113/113 [==============================] - 9s 77ms/step\n",
      "61/61 [==============================] - 4s 71ms/step\n",
      "150/150 [==============================] - 11s 73ms/step\n",
      "17/17 [==============================] - 1s 65ms/step\n",
      "[<tf.Tensor 'input_1_4:0' shape=(None, 100, 100, 3) dtype=float32>]\n",
      "163/163 [==============================] - 12s 73ms/step\n",
      "86/86 [==============================] - 6s 73ms/step\n",
      "79/79 [==============================] - 6s 73ms/step\n",
      "120/120 [==============================] - 9s 72ms/step\n",
      "35/35 [==============================] - 3s 73ms/step\n",
      "180/180 [==============================] - 13s 73ms/step\n",
      "  2/230 [..............................] - ETA: 6:51WARNING:tensorflow:Method (on_predict_batch_end) is slow compared to the batch update (1.987071). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_predict_batch_end) is slow compared to the batch update (1.987071). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 38s 163ms/step\n",
      "57/57 [==============================] - 5s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "MAX_RULS = {(3, 1): 23749,\n",
    " (3, 2): 19549,\n",
    " (3, 3): 4339,\n",
    " (4, 1): 11728,\n",
    " (4, 2): 7509,\n",
    " (5, 1): 24629,\n",
    " (5, 2): 23109,\n",
    " (6, 1): 24479,\n",
    " (6, 2): 7009,\n",
    " (7, 1): 22589,\n",
    " (7, 2): 2299,\n",
    " (1, 1): 28029,\n",
    " (1, 2): 9109,\n",
    " (1, 3): 5149,\n",
    " (2, 1): 8709,\n",
    " (2, 2): 7969,\n",
    " (2, 3): 16369\n",
    "}\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "\n",
    "    rna = tf.keras.models.load_model(f'../results/nets/{_dir}/{code}/{file}_{fold}.h5',\n",
    "                                    custom_objects={'LeakyReLU': tf.keras.layers.LeakyReLU,\n",
    "                                                    'NASAScore': scoring.NASAScore,\n",
    "                                                    'PHM21Score': scoring.PHM21Score,\n",
    "                                                    'SelfAttention': models.SelfAttention})\n",
    "    \n",
    "    print(rna.inputs)\n",
    "    channels = rna.inputs[0].shape[-1]\n",
    "    if channels > 3:\n",
    "        channels = 1\n",
    "    num_embeddings = rna.inputs[0].shape[1] * channels\n",
    "    \n",
    "    test_bearings = [i for i in range(1, 8) if i not in pronostia.FOLD_TRAIN_BEARINGS[fold]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for bearing in test_bearings:\n",
    "        embeddings_files = [f for f in os.listdir(f'../results/embeddings/{embeddings_dir}/fold_{fold}') \n",
    "                            if f.replace('.pk', '').split('_')[1] == str(bearing)]\n",
    "        \n",
    "        for embedding_file in embeddings_files:\n",
    "            condition = int(embedding_file.replace('.pk', '').split('_')[0])\n",
    "\n",
    "            embeddings = pk.load(open(f'../results/embeddings/{embeddings_dir}/fold_{fold}/{embedding_file}', \n",
    "                                      'rb'))\n",
    "            \n",
    "            \n",
    "            rul = RUL[(RUL.Bearing == bearing) & (RUL.Condition == condition)].RUL.values\n",
    "            t = [rul[i] for i in range(0, rul.shape[0], 100)][::-1]\n",
    "            rul = [rul[i] / MAX_RULS[(bearing, condition)] for i in range(0, rul.shape[0], 100)]\n",
    "            \n",
    "            \n",
    "            if len(rna.inputs[0].shape) == 3: #rnn\n",
    "                X = np.array([embeddings[i:i+num_embeddings] for i in range(len(embeddings)-num_embeddings)])\n",
    "                \n",
    "            else: #  cnn\n",
    "                X = np.array([embeddings[i:i+num_embeddings].T for i in range(len(embeddings)-num_embeddings)])\n",
    "                #X = np.expand_dims(X, axis=-1)\n",
    "                X = X.reshape((len(X),) + rna.inputs[0].shape[1:])\n",
    "            \n",
    "            T = [t[i+num_embeddings] for i in range(len(embeddings)-num_embeddings)]\n",
    "            R = [rul[i+num_embeddings] for i in range(len(embeddings)-num_embeddings)]\n",
    "            \n",
    "            pred = rna.predict(X, batch_size=256, verbose=1)\n",
    "            \n",
    "            \n",
    "            results.append({\n",
    "                'fold': fold,\n",
    "                'bearing': bearing,\n",
    "                'condition': condition,\n",
    "                'rul': R,\n",
    "                'pred': pred,\n",
    "                't': T\n",
    "            })\n",
    "            \n",
    "            del embeddings\n",
    "        \n",
    "          \n",
    "    del rna\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "pk.dump(results, open(f'../results/predictions/pronostia/{_dir}.pk', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
